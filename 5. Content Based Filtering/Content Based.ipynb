{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90bb4f2-4909-44f2-a2f1-61b84b1a40c0",
   "metadata": {},
   "source": [
    "# Content Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd669ffd-8fed-4f94-9c2e-bf37e6504598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import tqdm\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import average_precision_score, ndcg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f82c3a-c029-42f9-a370-9b3ced32e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data = pd.read_csv('../Dataset/customer_data_final.csv')\n",
    "purchase_history = pd.read_csv('../Dataset/purchase_history.csv')\n",
    "df = pd.read_csv('../Dataset/Item_data2.csv')\n",
    "\n",
    "gt1 = pd.read_csv('./ground_truth/Hair_Product_ground_truth_all_relevant.csv')\n",
    "gt2 = pd.read_csv('./ground_truth/Household_Product_ground_truth_all_relevant.csv')\n",
    "gt3 = pd.read_csv('./ground_truth/Beauty_Product_ground_truth_all_relevant.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebffde4b-2a3d-4daa-be39-857928edb582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Daniel\n",
      "[nltk_data]     Matias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Daniel\n",
      "[nltk_data]     Matias\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccab9c04-1dc0-430a-876f-5e2aed2388ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>ProdID_List</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>585.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  ProdID_List  Rating\n",
       "0  0.0        585.0       5\n",
       "1  0.0          6.0       3\n",
       "2  0.0          1.0       4\n",
       "3  0.0        532.0       5\n",
       "4  0.0         20.0       3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purchase_history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311752e1-f26f-44e6-aa08-4baf7f433f37",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55d49900-c652-4416-954a-545b1566d3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b265c4ea-c7e5-48a3-8319-f22e29814143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if pd.isna(text) or isinstance(text, (int, float)):\n",
    "        return '' \n",
    "    else:\n",
    "        tokens = text.split()\n",
    "        \n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "        \n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "        \n",
    "        return ' '.join(stemmed_tokens)\n",
    "\n",
    "# Apply preprocessing to specific columns\n",
    "df['Name'] = df['Name'].apply(preprocess_text)\n",
    "df['Category'] = df['Category'].apply(preprocess_text)\n",
    "df['Description'] = df['Description'].apply(preprocess_text)\n",
    "df['Tags'] = df['Tags'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faec7ab2-2748-40de-b0e2-93e94d03311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Combined_Text'] = (\n",
    "        df['Name'].fillna('') + ' ' +\n",
    "        df['Description'].fillna('') + ' ' +\n",
    "        df['Tags'].fillna('') + ' ' +\n",
    "        df['Brand'].fillna('') + ' ' +\n",
    "        df['price_bin'].fillna('').astype(str) + ' ' +\n",
    "        df['Category'].fillna('')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a6d13-9955-40b5-a768-d63ba30cb48e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc106b22-cb94-4299-a5f7-43b73253384b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_filtering_by_prodid(df, prod_id, prod_id_column='ProdID', name_column='Name', text_column='Combined_Text', \n",
    "                                      stop_words='english', ngram_range=(1, 2), top_n=10):\n",
    "    if prod_id not in df[prod_id_column].values:\n",
    "        return f\"ProdID {prod_id} not found in the dataset.\"\n",
    "\n",
    "    product_name = df.loc[df[prod_id_column] == prod_id, name_column].values[0]\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, ngram_range=ngram_range)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(df[text_column])\n",
    "    input_vector = tfidf_vectorizer.transform([product_name])\n",
    "\n",
    "    cosine_sim = cosine_similarity(input_vector, tfidf_matrix)\n",
    "    \n",
    "    similarities = pd.DataFrame({\n",
    "        prod_id_column: df[prod_id_column],\n",
    "        name_column: df[name_column],\n",
    "        'Rating': df['Rating'],\n",
    "        'RatingCount': df['RatingCount'],\n",
    "        'ReviewCount': df['ReviewCount'],\n",
    "        'Brand': df['Brand'],\n",
    "        'Price': df['Price'],\n",
    "        'ImageURL': df['ImageURL'],\n",
    "        'Tags': df['Tags'],\n",
    "        'Similarity': cosine_sim[0]\n",
    "    })\n",
    "    similarities = similarities[similarities[prod_id_column] != prod_id]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    similarities['Rating_Score'] = scaler.fit_transform(similarities[['Rating']])\n",
    "    similarities['RatingCount_Score'] = scaler.fit_transform(similarities[['RatingCount']])\n",
    "    similarities['ReviewCount_Score'] = scaler.fit_transform(similarities[['ReviewCount']])\n",
    "    \n",
    "    similarities['Final_Score'] = (\n",
    "        (0.5 * similarities['Rating_Score']) + \n",
    "        (0.3 * similarities['RatingCount_Score']) + \n",
    "        (0.2 * similarities['ReviewCount_Score'])\n",
    "    )\n",
    "\n",
    "    similarities = similarities.sort_values(by=['Similarity', 'Final_Score'], ascending=[False, False]).head(top_n)\n",
    "    \n",
    "    similarities.drop(columns=['Similarity', 'Rating_Score', 'RatingCount_Score', 'ReviewCount_Score', 'Final_Score'], inplace=True)\n",
    "\n",
    "    return product_name, similarities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a373cf7-6344-4c56-a0df-1f04674717b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Name: matrix high amplifi hair and duo 33.8 oz each\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>ImageURL</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2453</th>\n",
       "      <td>369.0</td>\n",
       "      <td>matrix total result mega sleek shea shampoo an...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>28.70</td>\n",
       "      <td>https://i5.walmartimages.com/asr/67be115a-22d6...</td>\n",
       "      <td>matrix, total, results, mega, sleek, shea, sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>3.0</td>\n",
       "      <td>matrix total result high amplifi proforma hair...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>22.50</td>\n",
       "      <td>https://i5.walmartimages.com/asr/aef445f9-6173...</td>\n",
       "      <td>matrix, total, results, high, amplify, proform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>3.0</td>\n",
       "      <td>matrix biolag colorlast wash for color treat h...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>21.90</td>\n",
       "      <td>https://i5.walmartimages.com/asr/1561e75a-6113...</td>\n",
       "      <td>matrix, biolage, colorlast, wash, color, treat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2.0</td>\n",
       "      <td>matrix biolag condit balm 8.5 oz - (pack of 2)</td>\n",
       "      <td>3.2</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>20.36</td>\n",
       "      <td>https://i5.walmartimages.com/asr/b3ba6ed3-62d8...</td>\n",
       "      <td>matrix, biolage, conditioning, balm, oz, pack,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>45.0</td>\n",
       "      <td>matrix 17628490 matrix biolag oil wonder flash...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>12.03</td>\n",
       "      <td>https://i5.walmartimages.com/asr/f33c87e3-25d6...</td>\n",
       "      <td>matrix, 17628490, matrix, biolage, oil, wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>61.0</td>\n",
       "      <td>matrix biolag hydrasourc daili leave-in</td>\n",
       "      <td>2.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>413.49</td>\n",
       "      <td>https://i5.walmartimages.com/asr/9b3f2f5f-b180...</td>\n",
       "      <td>matrix, biolage, hydrasource, daily, leave, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>3.0</td>\n",
       "      <td>matrix - biolag - fiberstrong fortifi cream - ...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>10.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/e08ad533-4650...</td>\n",
       "      <td>matrix, biolage, fiberstrong, fortifying, crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>765.0</td>\n",
       "      <td>matrix cream develop 10 volum - size : 16 oz</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>20.69</td>\n",
       "      <td>https://i5.walmartimages.com/asr/73be1f4f-6e2a...</td>\n",
       "      <td>matrix, cream, developer, 10, volume, size, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>226.0</td>\n",
       "      <td>biolag hydrasourc condit balm for dri hair by ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>matrix</td>\n",
       "      <td>18.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/4a0904fb-a101...</td>\n",
       "      <td>biolage, hydrasource, conditioning, balm, dry,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101</th>\n",
       "      <td>64933.0</td>\n",
       "      <td>pureolog hydrat conditioner, 33.8 oz</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>pureology</td>\n",
       "      <td>68.57</td>\n",
       "      <td>https://i5.walmartimages.com/asr/909554f4-cc0a...</td>\n",
       "      <td>pureology, hydrating, conditioner, oz, wal, mart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProdID                                               Name  Rating  \\\n",
       "2453    369.0  matrix total result mega sleek shea shampoo an...     5.0   \n",
       "2200      3.0  matrix total result high amplifi proforma hair...     5.0   \n",
       "2456      3.0  matrix biolag colorlast wash for color treat h...     4.0   \n",
       "179       2.0     matrix biolag condit balm 8.5 oz - (pack of 2)     3.2   \n",
       "305      45.0  matrix 17628490 matrix biolag oil wonder flash...     2.6   \n",
       "318      61.0            matrix biolag hydrasourc daili leave-in     2.9   \n",
       "1541      3.0  matrix - biolag - fiberstrong fortifi cream - ...     3.1   \n",
       "2896    765.0       matrix cream develop 10 volum - size : 16 oz     4.0   \n",
       "1975    226.0  biolag hydrasourc condit balm for dri hair by ...     5.0   \n",
       "2101  64933.0               pureolog hydrat conditioner, 33.8 oz     5.0   \n",
       "\n",
       "      RatingCount  ReviewCount      Brand   Price  \\\n",
       "2453          5.0          1.0     matrix   28.70   \n",
       "2200        175.0          4.0     matrix   22.50   \n",
       "2456        175.0          4.0     matrix   21.90   \n",
       "179         155.0          0.0     matrix   20.36   \n",
       "305          16.0          0.0     matrix   12.03   \n",
       "318          16.0         10.0     matrix  413.49   \n",
       "1541        175.0          0.0     matrix   10.99   \n",
       "2896         11.0          6.0     matrix   20.69   \n",
       "1975         41.0         21.0     matrix   18.99   \n",
       "2101         16.0         13.0  pureology   68.57   \n",
       "\n",
       "                                               ImageURL  \\\n",
       "2453  https://i5.walmartimages.com/asr/67be115a-22d6...   \n",
       "2200  https://i5.walmartimages.com/asr/aef445f9-6173...   \n",
       "2456  https://i5.walmartimages.com/asr/1561e75a-6113...   \n",
       "179   https://i5.walmartimages.com/asr/b3ba6ed3-62d8...   \n",
       "305   https://i5.walmartimages.com/asr/f33c87e3-25d6...   \n",
       "318   https://i5.walmartimages.com/asr/9b3f2f5f-b180...   \n",
       "1541  https://i5.walmartimages.com/asr/e08ad533-4650...   \n",
       "2896  https://i5.walmartimages.com/asr/73be1f4f-6e2a...   \n",
       "1975  https://i5.walmartimages.com/asr/4a0904fb-a101...   \n",
       "2101  https://i5.walmartimages.com/asr/909554f4-cc0a...   \n",
       "\n",
       "                                                   Tags  \n",
       "2453  matrix, total, results, mega, sleek, shea, sha...  \n",
       "2200  matrix, total, results, high, amplify, proform...  \n",
       "2456  matrix, biolage, colorlast, wash, color, treat...  \n",
       "179   matrix, biolage, conditioning, balm, oz, pack,...  \n",
       "305   matrix, 17628490, matrix, biolage, oil, wonder...  \n",
       "318   matrix, biolage, hydrasource, daily, leave, wa...  \n",
       "1541  matrix, biolage, fiberstrong, fortifying, crea...  \n",
       "2896  matrix, cream, developer, 10, volume, size, 16...  \n",
       "1975  biolage, hydrasource, conditioning, balm, dry,...  \n",
       "2101   pureology, hydrating, conditioner, oz, wal, mart  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_name, top_similarities = content_based_filtering_by_prodid(df, prod_id=67)\n",
    "print(f\"Product Name: {product_name}\")\n",
    "top_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f9538-584b-46ad-8f70-4c384d1e3895",
   "metadata": {},
   "source": [
    "## Search System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0fe3d7-b136-41c2-aa69-33e9872348c1",
   "metadata": {},
   "source": [
    "### Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5430ed63-b19f-48cc-a86d-42d82bcf22f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_multiple_columns(train_data, query, threshold=80):\n",
    "    def preprocess(text):\n",
    "        return re.sub(r'[^A-Za-z0-9\\s]+', '', text).strip().lower()\n",
    "\n",
    "    query_processed = preprocess(query)\n",
    "    best_match = None\n",
    "    best_score = -1\n",
    "\n",
    "    for column in ['Name', 'Brand', 'Tags', 'Description', 'Category']:\n",
    "        candidates = train_data[column].fillna('').astype(str)\n",
    "        for candidate in candidates:\n",
    "            candidate_processed = preprocess(candidate)\n",
    "            score = fuzz.token_sort_ratio(query_processed, candidate_processed)\n",
    "            if score > best_score and score >= threshold:\n",
    "                best_score = score\n",
    "                best_match = candidate\n",
    "    \n",
    "    return best_match, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2720a4-d0b0-4aa1-914f-77d6d8bd2dd6",
   "metadata": {},
   "source": [
    "### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919d5122-7c4c-42a2-8d9c-4a8620cc0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_synonyms(term):\n",
    "        synonyms = set()\n",
    "        for synset in wordnet.synsets(term):\n",
    "            for lemma in synset.lemmas():\n",
    "                synonyms.add(lemma.name().replace('_', ' '))\n",
    "        return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13204bd1-6390-47b0-b4bf-c21f14cadc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query_with_synonyms(query):\n",
    "        query_terms = query.lower().split()\n",
    "        expanded_terms = query_terms.copy()\n",
    "\n",
    "        for term in query_terms:\n",
    "            synonyms = get_synonyms(term)\n",
    "            expanded_terms.extend(synonyms)\n",
    "\n",
    "        return \" \".join(set(expanded_terms))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638bc140-5f72-4c0c-9c7c-1d0c1b906812",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### System System 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edbe2b5-ab4a-48be-90b8-9223c0fbf19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendations(train_data, item_name, top_n=50, name_weight=0.2, description_weight=0.2, tags_weight=0.2, brand_weight=0.2, category_weight=0.2):\n",
    "    item_name_lower = preprocess_text(item_name)\n",
    "    \n",
    "    item_name_lower = expand_query_with_synonyms(item_name_lower)\n",
    "    query_terms = item_name_lower.split()\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "\n",
    "    combined_matches = pd.DataFrame()\n",
    "\n",
    "    for term in query_terms:\n",
    "        name_match = train_data[train_data['Name'].str.lower().str.contains(term, case=False, na=False)]\n",
    "        brand_match = train_data[train_data['Brand'].str.lower().str.contains(term, case=False, na=False)]\n",
    "        tags_match = train_data[train_data['Tags'].str.lower().str.contains(term, case=False, na=False)]\n",
    "        description_match = train_data[train_data['Description'].str.lower().str.contains(term, case=False, na=False)]\n",
    "        category_match = train_data[train_data['Category'].str.lower().str.contains(term, case=False, na=False)]\n",
    "\n",
    "        term_matches = pd.concat([name_match, brand_match, tags_match, description_match, category_match]).drop_duplicates()\n",
    "        \n",
    "        combined_matches = pd.concat([combined_matches, term_matches]).drop_duplicates()\n",
    "\n",
    "    if combined_matches.empty:\n",
    "        print(f\"No exact match found for '{item_name_lower}'. Attempting fuzzy matching...\")\n",
    "        fuzzy_match, fuzzy_score = fuzzy_match_multiple_columns(train_data, item_name_lower)\n",
    "        \n",
    "        if fuzzy_match and fuzzy_score >= 80:\n",
    "            print(f\"Fuzzy match found: '{fuzzy_match}' with score: {fuzzy_score}\")\n",
    "            \n",
    "            name_match = train_data[train_data['Name'].str.lower().str.contains(fuzzy_match.lower(), case=False, na=False)]\n",
    "            brand_match = train_data[train_data['Brand'].str.lower().str.contains(fuzzy_match.lower(), case=False, na=False)]\n",
    "            tags_match = train_data[train_data['Tags'].str.lower().str.contains(fuzzy_match.lower(), case=False, na=False)]\n",
    "            description_match = train_data[train_data['Description'].str.lower().str.contains(fuzzy_match.lower(), case=False, na=False)]\n",
    "            category_match = train_data[train_data['Category'].str.lower().str.contains(fuzzy_match.lower(), case=False, na=False)]\n",
    "\n",
    "            combined_matches = pd.concat([name_match, brand_match, tags_match, description_match, category_match]).drop_duplicates()\n",
    "\n",
    "    if combined_matches.empty:\n",
    "        print(f\"No match found for '{item_name_lower}'. Returning most similar result based on combined features.\")\n",
    "    \n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Combined_Text'])\n",
    "        \n",
    "        input_vector = tfidf_vectorizer.transform([item_name_lower])\n",
    "\n",
    "        cosine_sim = cosine_similarity(input_vector, tfidf_matrix)\n",
    "\n",
    "        most_similar_item_index = cosine_sim.argmax() \n",
    "        exact_match = train_data.iloc[[most_similar_item_index]] \n",
    "        print(f\"Most similar item found: '{exact_match['Name'].values[0]}'\")\n",
    "        combined_matches = exact_match\n",
    "\n",
    "    if not combined_matches.empty:\n",
    "        print(f\"Found match for '{item_name_lower}'. Showing similar items.\")\n",
    "        \n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Combined_Text'])\n",
    "        \n",
    "        name_vector = tfidf_vectorizer.transform(train_data['Name'].fillna(''))\n",
    "        description_vector = tfidf_vectorizer.transform(train_data['Description'].fillna(''))\n",
    "        tags_vector = tfidf_vectorizer.transform(train_data['Tags'].fillna(''))\n",
    "        brand_vector = tfidf_vectorizer.transform(train_data['Brand'].fillna(''))\n",
    "        category_vector = tfidf_vectorizer.transform(train_data['Category'].fillna(''))\n",
    "        \n",
    "        weighted_matrix = (\n",
    "            (name_weight * name_vector) + \n",
    "            (description_weight * description_vector) + \n",
    "            (tags_weight * tags_vector) + \n",
    "            (brand_weight * brand_vector) + \n",
    "            (category_weight * category_vector)\n",
    "        )\n",
    "\n",
    "        weighted_matrix_normalized = normalize(weighted_matrix, norm='l2')\n",
    "\n",
    "        cosine_sim = cosine_similarity(weighted_matrix_normalized, weighted_matrix_normalized)\n",
    "\n",
    "        match_indices = combined_matches.index.tolist()\n",
    "        similar_items = sorted(list(enumerate(cosine_sim[match_indices].mean(axis=0))), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        top_similar_items = similar_items[1:top_n+1]\n",
    "        recommended_items_indices = [x[0] for x in top_similar_items if x[0] < len(train_data)]\n",
    "\n",
    "        recommended_items = train_data.iloc[recommended_items_indices][['ProdID', 'Name', 'Rating', 'RatingCount', 'ReviewCount', 'Brand', 'Price', 'ImageURL', 'Tags']]\n",
    "        \n",
    "        recommended_items['Rating_Score'] = recommended_items['Rating'].rank(ascending=False, method='min')\n",
    "        recommended_items['RatingCount_Score'] = recommended_items['RatingCount'].rank(ascending=False, method='min')\n",
    "        recommended_items['ReviewCount_Score'] = recommended_items['ReviewCount'].rank(ascending=False, method='min')\n",
    "\n",
    "        recommended_items['Final_Score'] = (\n",
    "            (0.5 * recommended_items['Rating_Score']) + \n",
    "            (0.3 * recommended_items['RatingCount_Score']) + \n",
    "            (0.2 * recommended_items['ReviewCount_Score'])\n",
    "        )\n",
    "\n",
    "        recommended_items = recommended_items.sort_values(by='Final_Score', ascending=True)\n",
    "        \n",
    "        return recommended_items.drop(columns=['Rating_Score', 'RatingCount_Score', 'ReviewCount_Score', 'Final_Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dd66a9e-f973-4239-a7d0-c566ef00e1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'loreal'. Showing similar items.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>ImageURL</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>7.0</td>\n",
       "      <td>loreal pari excel creme perman tripl protect h...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12494.0</td>\n",
       "      <td>6494.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>7.91</td>\n",
       "      <td>https://i5.walmartimages.com/asr/5ffb3626-4031...</td>\n",
       "      <td>paris, excellence, creme, permanent, triple, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>0.0</td>\n",
       "      <td>loreal pari superior prefer fade-defi shine pe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3348.0</td>\n",
       "      <td>2077.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>8.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/3eae3d0b-b23e...</td>\n",
       "      <td>paris, superior, preference, fade, defying, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>6249.0</td>\n",
       "      <td>loreal pari colour rich origin satin lipstick ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>5.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/6a105452-4523...</td>\n",
       "      <td>paris, colour, riche, original, satin, lipstic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>76.0</td>\n",
       "      <td>loreal pari superior prefer fade-defi shine pe...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>8.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/762fd9f2-3624...</td>\n",
       "      <td>paris, superior, preference, fade, defying, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>2.0</td>\n",
       "      <td>loreal pari colour rich glossi balm, innoc coral</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>20.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/a313e50a-5f82...</td>\n",
       "      <td>paris, colour, riche, glossy, balm, innocent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>8.0</td>\n",
       "      <td>loreal pari excel creme tripl protect hair col...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>62.81</td>\n",
       "      <td>https://i5.walmartimages.com/asr/3801e2fa-7a12...</td>\n",
       "      <td>paris, excellence, creme, triple, protection, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>6.0</td>\n",
       "      <td>loreal pari superior prefer fade-defi shine pe...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2618.0</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>8.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/826d9eed-5b6d...</td>\n",
       "      <td>paris, superior, preference, fade, defying, sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>76.0</td>\n",
       "      <td>loreal pari colour rich origin satin lipstick ...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>794.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>5.82</td>\n",
       "      <td>https://i5.walmartimages.com/asr/76d82d8d-ff90...</td>\n",
       "      <td>paris, colour, riche, original, satin, lipstic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>loreal pari excel creme tripl protect color cr...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>7.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/4becac6c-e293...</td>\n",
       "      <td>paris, excellence, creme, triple, protection, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>4.0</td>\n",
       "      <td>loreal pari colour rich collect exclus lipstick</td>\n",
       "      <td>3.2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>4.12</td>\n",
       "      <td>https://i5.walmartimages.com/asr/c654a699-1a19...</td>\n",
       "      <td>paris, colour, riche, collection, exclusive, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ProdID                                               Name  Rating  \\\n",
       "3653     7.0  loreal pari excel creme perman tripl protect h...     4.0   \n",
       "2273     0.0  loreal pari superior prefer fade-defi shine pe...     4.0   \n",
       "632   6249.0  loreal pari colour rich origin satin lipstick ...     4.0   \n",
       "2993    76.0  loreal pari superior prefer fade-defi shine pe...     3.8   \n",
       "3890     2.0   loreal pari colour rich glossi balm, innoc coral     4.0   \n",
       "1226     8.0  loreal pari excel creme tripl protect hair col...     5.0   \n",
       "1903     6.0  loreal pari superior prefer fade-defi shine pe...     3.7   \n",
       "1485    76.0  loreal pari colour rich origin satin lipstick ...     3.6   \n",
       "1        6.0  loreal pari excel creme tripl protect color cr...     3.6   \n",
       "1731     4.0    loreal pari colour rich collect exclus lipstick     3.2   \n",
       "\n",
       "      RatingCount  ReviewCount  Brand  Price  \\\n",
       "3653      12494.0       6494.0  paris   7.91   \n",
       "2273       3348.0       2077.0  paris   8.97   \n",
       "632        1029.0        794.0  paris   5.97   \n",
       "2993       1941.0       1582.0  paris   8.97   \n",
       "3890        155.0         41.0  paris  20.99   \n",
       "1226        141.0          1.0  paris  62.81   \n",
       "1903       2618.0       1506.0  paris   8.97   \n",
       "1485       1430.0        794.0  paris   5.82   \n",
       "1          1143.0        760.0  paris   7.97   \n",
       "1731        140.0         31.0  paris   4.12   \n",
       "\n",
       "                                               ImageURL  \\\n",
       "3653  https://i5.walmartimages.com/asr/5ffb3626-4031...   \n",
       "2273  https://i5.walmartimages.com/asr/3eae3d0b-b23e...   \n",
       "632   https://i5.walmartimages.com/asr/6a105452-4523...   \n",
       "2993  https://i5.walmartimages.com/asr/762fd9f2-3624...   \n",
       "3890  https://i5.walmartimages.com/asr/a313e50a-5f82...   \n",
       "1226  https://i5.walmartimages.com/asr/3801e2fa-7a12...   \n",
       "1903  https://i5.walmartimages.com/asr/826d9eed-5b6d...   \n",
       "1485  https://i5.walmartimages.com/asr/76d82d8d-ff90...   \n",
       "1     https://i5.walmartimages.com/asr/4becac6c-e293...   \n",
       "1731  https://i5.walmartimages.com/asr/c654a699-1a19...   \n",
       "\n",
       "                                                   Tags  \n",
       "3653  paris, excellence, creme, permanent, triple, p...  \n",
       "2273  paris, superior, preference, fade, defying, sh...  \n",
       "632   paris, colour, riche, original, satin, lipstic...  \n",
       "2993  paris, superior, preference, fade, defying, sh...  \n",
       "3890  paris, colour, riche, glossy, balm, innocent, ...  \n",
       "1226  paris, excellence, creme, triple, protection, ...  \n",
       "1903  paris, superior, preference, fade, defying, sh...  \n",
       "1485  paris, colour, riche, original, satin, lipstic...  \n",
       "1     paris, excellence, creme, triple, protection, ...  \n",
       "1731  paris, colour, riche, collection, exclusive, l...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name = \"loreal\"  # The item the user is searching for\n",
    "\n",
    "# Call the content-based recommendation function\n",
    "recommended_items = content_based_recommendations(\n",
    "    train_data=df,\n",
    "    item_name=item_name,\n",
    "    top_n=10  # Number of top recommendations to retrieve\n",
    ")\n",
    "\n",
    "# Display recommended iteams\n",
    "recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07d0e1bb-dc9b-4445-87c0-7c9aa7a2417a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'shampoo'. Showing similar items.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>ImageURL</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>4.166700e+04</td>\n",
       "      <td>head and shoulder old spice pure sport dandruf...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>534.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>head, shoulders</td>\n",
       "      <td>5.24</td>\n",
       "      <td>https://i5.walmartimages.com/asr/a9b3c1ff-e011...</td>\n",
       "      <td>head, shoulders, old, spice, pure, sport, dand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>loreal pari elviv extraordinari clay rebalanc ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1891.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>3.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/dd6fa9f0-4180...</td>\n",
       "      <td>paris, elvive, extraordinary, clay, rebalancin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2071</th>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>paul mitchel awapuhi wild ginger moistur lathe...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>paul, mitchell</td>\n",
       "      <td>47.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/9c2b4e1b-3b34...</td>\n",
       "      <td>paul, mitchell, awapuhi, wild, ginger, moistur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>panten nutrient blend shampoo, damag repair, 9...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>141.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>pantene</td>\n",
       "      <td>6.97</td>\n",
       "      <td>https://i5.walmartimages.com/asr/74e506f4-8667...</td>\n",
       "      <td>pantene, nutrient, blends, shampoo, damage, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>3.076159e+12</td>\n",
       "      <td>big sexi hair big volum shampoo sexi hair 33.8...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sexy, hair</td>\n",
       "      <td>14.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/149c88e0-b4a7...</td>\n",
       "      <td>big, sexy, hair, big, volume, shampoo, sexy, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3605</th>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>garnier whole blend smooth shampoo with coconu...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>15073.0</td>\n",
       "      <td>9799.0</td>\n",
       "      <td>garnier</td>\n",
       "      <td>3.47</td>\n",
       "      <td>https://i5.walmartimages.com/asr/70da3e89-1984...</td>\n",
       "      <td>garnier, blends, smoothing, shampoo, coconut, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>panten pro-v classic clean 2 in 1 shampoo &amp; co...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>571.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>pantene</td>\n",
       "      <td>36.98</td>\n",
       "      <td>https://i5.walmartimages.com/asr/846e55e8-aade...</td>\n",
       "      <td>pantene, pro, v, classic, clean, 2, 1, shampoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>3.830000e+02</td>\n",
       "      <td>finess 2 in 1 textur enhanc shampoo &amp; conditio...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>finesse</td>\n",
       "      <td>24.76</td>\n",
       "      <td>https://i5.walmartimages.com/asr/6d1a79fc-45b7...</td>\n",
       "      <td>finesse, 2, 1, texture, enhancing, shampoo, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>7.100000e+01</td>\n",
       "      <td>finess 2 in 1 moistur shampoo and condition 24...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>finesse</td>\n",
       "      <td>24.15</td>\n",
       "      <td>https://i5.walmartimages.com/asr/4dd8bfba-387a...</td>\n",
       "      <td>finesse, 2, 1, moisturizing, shampoo, conditio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>2.903660e+05</td>\n",
       "      <td>rusk sensori pure mandarin and jasmin shampoo ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rusk</td>\n",
       "      <td>13.99</td>\n",
       "      <td>https://i5.walmartimages.com/asr/736ac3be-6c68...</td>\n",
       "      <td>rusk, sensories, pure, mandarin, jasmine, sham...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ProdID                                               Name  Rating  \\\n",
       "3216  4.166700e+04  head and shoulder old spice pure sport dandruf...     4.6   \n",
       "3881  2.000000e+00  loreal pari elviv extraordinari clay rebalanc ...     4.4   \n",
       "2071  2.400000e+01  paul mitchel awapuhi wild ginger moistur lathe...     5.0   \n",
       "2235  8.000000e+00  panten nutrient blend shampoo, damag repair, 9...     4.6   \n",
       "2706  3.076159e+12  big sexi hair big volum shampoo sexi hair 33.8...     5.0   \n",
       "3605  7.000000e+00  garnier whole blend smooth shampoo with coconu...     3.3   \n",
       "1672  5.000000e+00  panten pro-v classic clean 2 in 1 shampoo & co...     3.9   \n",
       "3729  3.830000e+02  finess 2 in 1 textur enhanc shampoo & conditio...     4.0   \n",
       "2234  7.100000e+01  finess 2 in 1 moistur shampoo and condition 24...     2.9   \n",
       "1154  2.903660e+05  rusk sensori pure mandarin and jasmin shampoo ...     2.0   \n",
       "\n",
       "      RatingCount  ReviewCount            Brand  Price  \\\n",
       "3216        534.0        358.0  head, shoulders   5.24   \n",
       "3881       2008.0       1891.0            paris   3.97   \n",
       "2071         11.0          1.0   paul, mitchell  47.99   \n",
       "2235        141.0         96.0          pantene   6.97   \n",
       "2706          5.0          1.0       sexy, hair  14.99   \n",
       "3605      15073.0       9799.0          garnier   3.47   \n",
       "1672        571.0        336.0          pantene  36.98   \n",
       "3729          2.0          1.0          finesse  24.76   \n",
       "2234         15.0          0.0          finesse  24.15   \n",
       "1154          1.0          0.0             rusk  13.99   \n",
       "\n",
       "                                               ImageURL  \\\n",
       "3216  https://i5.walmartimages.com/asr/a9b3c1ff-e011...   \n",
       "3881  https://i5.walmartimages.com/asr/dd6fa9f0-4180...   \n",
       "2071  https://i5.walmartimages.com/asr/9c2b4e1b-3b34...   \n",
       "2235  https://i5.walmartimages.com/asr/74e506f4-8667...   \n",
       "2706  https://i5.walmartimages.com/asr/149c88e0-b4a7...   \n",
       "3605  https://i5.walmartimages.com/asr/70da3e89-1984...   \n",
       "1672  https://i5.walmartimages.com/asr/846e55e8-aade...   \n",
       "3729  https://i5.walmartimages.com/asr/6d1a79fc-45b7...   \n",
       "2234  https://i5.walmartimages.com/asr/4dd8bfba-387a...   \n",
       "1154  https://i5.walmartimages.com/asr/736ac3be-6c68...   \n",
       "\n",
       "                                                   Tags  \n",
       "3216  head, shoulders, old, spice, pure, sport, dand...  \n",
       "3881  paris, elvive, extraordinary, clay, rebalancin...  \n",
       "2071  paul, mitchell, awapuhi, wild, ginger, moistur...  \n",
       "2235  pantene, nutrient, blends, shampoo, damage, re...  \n",
       "2706  big, sexy, hair, big, volume, shampoo, sexy, h...  \n",
       "3605  garnier, blends, smoothing, shampoo, coconut, ...  \n",
       "1672  pantene, pro, v, classic, clean, 2, 1, shampoo...  \n",
       "3729  finesse, 2, 1, texture, enhancing, shampoo, co...  \n",
       "2234  finesse, 2, 1, moisturizing, shampoo, conditio...  \n",
       "1154  rusk, sensories, pure, mandarin, jasmine, sham...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name = \"shampoo\"  # The item the user is searching for\n",
    "\n",
    "# Call the content-based recommendation function\n",
    "recommended_items = content_based_recommendations(\n",
    "    train_data=df,\n",
    "    item_name=item_name,\n",
    "    top_n=10  # Number of top recommendations to retrieve\n",
    ")\n",
    "\n",
    "# Display recommended iteams\n",
    "recommended_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a019fd-24cb-4701-a616-4d27c24b105f",
   "metadata": {},
   "source": [
    "### Search System 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f45c5fe7-78eb-4b58-a8c1-433d4d0878b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_based_recommendations2(train_data, item_name, top_n=50, \n",
    "                                  exact_match_weight=1.0, \n",
    "                                  ai_vector_weight=0.9, \n",
    "                                  category_weight=0.7, \n",
    "                                  word_search_weight=0.5, \n",
    "                                  fuzzy_weight=0.3):\n",
    "    \n",
    "    item_name_lower = preprocess_text(item_name)\n",
    "    item_name_expanded = expand_query_with_synonyms(item_name_lower)\n",
    "    query_terms = item_name_expanded.split()\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2))\n",
    "    train_data['Combined_Text'] = (\n",
    "        train_data['Name'].fillna('') + ' ' + \n",
    "        train_data['Description'].fillna('') + ' ' +\n",
    "        train_data['Tags'].fillna('') + ' ' + \n",
    "        train_data['Brand'].fillna('') + ' ' + \n",
    "        train_data['Category'].fillna('')\n",
    "    )\n",
    "\n",
    "    # Step 1: Exact Match\n",
    "    exact_matches = pd.DataFrame()\n",
    "    for term in query_terms:\n",
    "        exact_match = train_data[train_data['Name'].str.lower().str.contains(term, case=False, na=False)]\n",
    "        exact_matches = pd.concat([exact_matches, exact_match]).drop_duplicates()\n",
    "\n",
    "    if not exact_matches.empty:\n",
    "        exact_matches['Score'] = exact_match_weight\n",
    "        combined_matches = exact_matches\n",
    "    else:\n",
    "        combined_matches = pd.DataFrame()\n",
    "\n",
    "    # Step 2: AI Vector Search (TF-IDF with Cosine Similarity)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Combined_Text'])\n",
    "    input_vector = tfidf_vectorizer.transform([item_name_expanded])\n",
    "    cosine_sim = cosine_similarity(input_vector, tfidf_matrix)\n",
    "    \n",
    "    ai_vector_matches = train_data.copy()\n",
    "    ai_vector_matches['Similarity'] = cosine_sim[0]\n",
    "    ai_vector_matches = ai_vector_matches[ai_vector_matches['Similarity'] > 0]\n",
    "    ai_vector_matches['Score'] = ai_vector_matches['Similarity'] * ai_vector_weight\n",
    "    \n",
    "    combined_matches = pd.concat([combined_matches, ai_vector_matches]).drop_duplicates()\n",
    "\n",
    "    # Step 3: Category Match\n",
    "    category_matches = train_data[train_data['Category'].str.lower().str.contains(item_name_lower, case=False, na=False)]\n",
    "    if not category_matches.empty:\n",
    "        category_matches.loc[:, 'Score'] = category_weight\n",
    "        combined_matches = pd.concat([combined_matches, category_matches]).drop_duplicates()\n",
    "\n",
    "    # Step 4: Word Search (using expanded terms)\n",
    "    word_search_matches = pd.DataFrame()\n",
    "    for term in query_terms:\n",
    "        word_match = train_data[\n",
    "            train_data['Name'].str.lower().str.contains(term, case=False, na=False) |\n",
    "            train_data['Brand'].str.lower().str.contains(term, case=False, na=False) |\n",
    "            train_data['Tags'].str.lower().str.contains(term, case=False, na=False) |\n",
    "            train_data['Description'].str.lower().str.contains(term, case=False, na=False) |\n",
    "            train_data['Category'].str.lower().str.contains(term, case=False, na=False)\n",
    "        ]\n",
    "        word_search_matches = pd.concat([word_search_matches, word_match]).drop_duplicates()\n",
    "        \n",
    "    if not word_search_matches.empty:\n",
    "        word_search_matches['Score'] = word_search_weight\n",
    "        combined_matches = pd.concat([combined_matches, word_search_matches]).drop_duplicates()\n",
    "\n",
    "    # Step 5: Fuzzy Search\n",
    "    fuzzy_matches = pd.DataFrame()\n",
    "    for column in ['Name', 'Brand', 'Tags', 'Description', 'Category']:\n",
    "        candidates = train_data[column].fillna('').astype(str)\n",
    "        for candidate in candidates:\n",
    "            candidate_processed = preprocess_text(candidate)\n",
    "            score = fuzz.token_sort_ratio(item_name_lower, candidate_processed)\n",
    "            if score >= 80:  # threshold for fuzzy matching\n",
    "                match = train_data[train_data[column].str.lower() == candidate_processed]\n",
    "                match['Score'] = score / 100 * fuzzy_weight\n",
    "                fuzzy_matches = pd.concat([fuzzy_matches, match]).drop_duplicates()\n",
    "\n",
    "    combined_matches = pd.concat([combined_matches, fuzzy_matches]).drop_duplicates()\n",
    "\n",
    "    # Combine Scores and Rank by Content-Based Score\n",
    "    combined_matches['Final_Score'] = combined_matches.groupby(['ProdID'])['Score'].transform('sum')\n",
    "    recommended_items = combined_matches.sort_values(by='Final_Score', ascending=False).drop_duplicates('ProdID').head(top_n)\n",
    "\n",
    "    # Additional Ranking Based on Ratings, RatingCount, and ReviewCount\n",
    "    recommended_items['Rating_Score'] = recommended_items['Rating'].rank(ascending=False, method='min')\n",
    "    recommended_items['RatingCount_Score'] = recommended_items['RatingCount'].rank(ascending=False, method='min')\n",
    "    recommended_items['ReviewCount_Score'] = recommended_items['ReviewCount'].rank(ascending=False, method='min')\n",
    "\n",
    "    recommended_items['Final_Score'] = (\n",
    "        (0.5 * recommended_items['Rating_Score']) + \n",
    "        (0.3 * recommended_items['RatingCount_Score']) + \n",
    "        (0.2 * recommended_items['ReviewCount_Score'])\n",
    "    )\n",
    "\n",
    "    recommended_items = recommended_items.sort_values(by='Final_Score', ascending=True)\n",
    "    \n",
    "    return recommended_items[['ProdID', 'Name', 'Rating', 'RatingCount', 'ReviewCount', 'Brand', 'Price', 'Tags']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "628e53ff-9f43-4286-871e-0a4a8dbb7f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>7.0</td>\n",
       "      <td>loreal pari excel creme perman tripl protect h...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12494.0</td>\n",
       "      <td>6494.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>7.91</td>\n",
       "      <td>paris, excellence, creme, permanent, triple, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>3.0</td>\n",
       "      <td>loreal pari infal pro last 2 step lipstick, pe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>751.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>9.98</td>\n",
       "      <td>paris, infallible, pro, 2, step, lipstick, per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>5.0</td>\n",
       "      <td>etern mauv 520 by loreal for women lipstick</td>\n",
       "      <td>4.8</td>\n",
       "      <td>154.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>6.47</td>\n",
       "      <td>eternally, mauve, 520, women, lipstick, wal, mart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>loreal pari excel creme tripl protect color cr...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>7.97</td>\n",
       "      <td>paris, excellence, creme, triple, protection, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3851</th>\n",
       "      <td>1.0</td>\n",
       "      <td>loreal pari colorista hair makeup temporari 1-...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1855.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>8.97</td>\n",
       "      <td>paris, colorista, hair, makeup, temporary, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3875</th>\n",
       "      <td>8.0</td>\n",
       "      <td>loreal pari colour rich lip liner, last plum, ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>5.82</td>\n",
       "      <td>paris, colour, riche, lip, liner, lasting, plu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>2.0</td>\n",
       "      <td>loreal pari colour rich glossi balm, innoc coral</td>\n",
       "      <td>4.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>20.99</td>\n",
       "      <td>paris, colour, riche, glossy, balm, innocent, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>9.0</td>\n",
       "      <td>loreal profession majicontrast - red - 1.7 oz ...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>professionnel</td>\n",
       "      <td>14.07</td>\n",
       "      <td>loreal, professional, majicontrast, red, oz, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>loreal pari excel non-drip creme hair color, r...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>164.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>31.44</td>\n",
       "      <td>paris, excellence, non, drip, creme, hair, col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2 pack - loreal pari revitalift doubl lift eye...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>professionnel</td>\n",
       "      <td>24.45</td>\n",
       "      <td>2, pack, paris, revitalift, double, lifting, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ProdID                                               Name  Rating  \\\n",
       "3653     7.0  loreal pari excel creme perman tripl protect h...     4.0   \n",
       "63       3.0  loreal pari infal pro last 2 step lipstick, pe...     4.0   \n",
       "1034     5.0        etern mauv 520 by loreal for women lipstick     4.8   \n",
       "1        6.0  loreal pari excel creme tripl protect color cr...     3.6   \n",
       "3851     1.0  loreal pari colorista hair makeup temporari 1-...     3.4   \n",
       "3875     8.0  loreal pari colour rich lip liner, last plum, ...     4.4   \n",
       "3890     2.0   loreal pari colour rich glossi balm, innoc coral     4.0   \n",
       "2375     9.0  loreal profession majicontrast - red - 1.7 oz ...     2.9   \n",
       "3124     0.0  loreal pari excel non-drip creme hair color, r...     2.7   \n",
       "2335     4.0  2 pack - loreal pari revitalift doubl lift eye...     3.2   \n",
       "\n",
       "      RatingCount  ReviewCount          Brand  Price  \\\n",
       "3653      12494.0       6494.0          paris   7.91   \n",
       "63          751.0        461.0          paris   9.98   \n",
       "1034        154.0         53.0          paris   6.47   \n",
       "1          1143.0        760.0          paris   7.97   \n",
       "3851       1855.0       1006.0          paris   8.97   \n",
       "3875        141.0         85.0          paris   5.82   \n",
       "3890        155.0         41.0          paris  20.99   \n",
       "2375        157.0          0.0  professionnel  14.07   \n",
       "3124        164.0          0.0          paris  31.44   \n",
       "2335        140.0         47.0  professionnel  24.45   \n",
       "\n",
       "                                                   Tags  \n",
       "3653  paris, excellence, creme, permanent, triple, p...  \n",
       "63    paris, infallible, pro, 2, step, lipstick, per...  \n",
       "1034  eternally, mauve, 520, women, lipstick, wal, mart  \n",
       "1     paris, excellence, creme, triple, protection, ...  \n",
       "3851  paris, colorista, hair, makeup, temporary, 1, ...  \n",
       "3875  paris, colour, riche, lip, liner, lasting, plu...  \n",
       "3890  paris, colour, riche, glossy, balm, innocent, ...  \n",
       "2375  loreal, professional, majicontrast, red, oz, h...  \n",
       "3124  paris, excellence, non, drip, creme, hair, col...  \n",
       "2335  2, pack, paris, revitalift, double, lifting, e...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name = \"loreal\"  \n",
    "\n",
    "recommended_items = content_based_recommendations2(\n",
    "    train_data=df,\n",
    "    item_name=item_name,\n",
    "    top_n=10 \n",
    ")\n",
    "\n",
    "recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b669e2-7fcc-47e6-9cd6-d2ad465f2979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_6360\\2564313212.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProdID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>RatingCount</th>\n",
       "      <th>ReviewCount</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Price</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>loreal pari magic root cover up conceal spray,...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11721.0</td>\n",
       "      <td>6955.0</td>\n",
       "      <td>paris</td>\n",
       "      <td>9.97</td>\n",
       "      <td>paris, magic, root, cover, concealer, spray, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>redken color extend magnet sulfate-fre shampoo...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>505.0</td>\n",
       "      <td>326.0</td>\n",
       "      <td>redken</td>\n",
       "      <td>30.00</td>\n",
       "      <td>redken, color, extend, magnetics, sulfate, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>1.007940e+42</td>\n",
       "      <td>suav profession coconut milk infus intens mois...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>246.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>suave</td>\n",
       "      <td>13.53</td>\n",
       "      <td>suave, professionals, coconut, milk, infusion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>just for men color gel mustach &amp; beard m-35 me...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2257.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>men</td>\n",
       "      <td>40.68</td>\n",
       "      <td>men, color, gel, mustache, beard, medium, brow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3666</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>ogx ever straighten + brazilian keratin therap...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>796.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>ogx</td>\n",
       "      <td>21.00</td>\n",
       "      <td>ogx, straightening, brazilian, keratin, therap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>panten pro-v classic clean 2 in 1 shampoo &amp; co...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>571.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>pantene</td>\n",
       "      <td>36.98</td>\n",
       "      <td>pantene, pro, v, classic, clean, 2, 1, shampoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1701</th>\n",
       "      <td>5.600000e+01</td>\n",
       "      <td>splat hair chalk (sugar plum)</td>\n",
       "      <td>4.2</td>\n",
       "      <td>56.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>splat</td>\n",
       "      <td>6.89</td>\n",
       "      <td>splat, hair, chalk, sugar, plum, wal, mart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>volum therapi shampoo by biosilk for unisex - ...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>biosilk</td>\n",
       "      <td>25.87</td>\n",
       "      <td>volumizing, therapy, shampoo, biosilk, unisex,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2434</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>panten pro-v smooth &amp; sleek conditioner, 23.7 ...</td>\n",
       "      <td>2.7</td>\n",
       "      <td>164.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>pantene</td>\n",
       "      <td>29.90</td>\n",
       "      <td>pantene, pro, v, smooth, sleek, conditioner, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>blue neon color pigment powder for craft soap ...</td>\n",
       "      <td>2.9</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oils, center</td>\n",
       "      <td>12.19</td>\n",
       "      <td>blue, neon, colorant, pigment, powder, crafts,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ProdID                                               Name  Rating  \\\n",
       "1605  4.000000e+00  loreal pari magic root cover up conceal spray,...     4.0   \n",
       "2989  8.000000e+00  redken color extend magnet sulfate-fre shampoo...     4.5   \n",
       "975   1.007940e+42  suav profession coconut milk infus intens mois...     4.6   \n",
       "2755  2.000000e+00  just for men color gel mustach & beard m-35 me...     3.2   \n",
       "3666  1.000000e+00  ogx ever straighten + brazilian keratin therap...     3.2   \n",
       "1672  5.000000e+00  panten pro-v classic clean 2 in 1 shampoo & co...     3.9   \n",
       "1701  5.600000e+01                      splat hair chalk (sugar plum)     4.2   \n",
       "3600  3.000000e+00  volum therapi shampoo by biosilk for unisex - ...     3.1   \n",
       "2434  0.000000e+00  panten pro-v smooth & sleek conditioner, 23.7 ...     2.7   \n",
       "3013  9.000000e+00  blue neon color pigment powder for craft soap ...     2.9   \n",
       "\n",
       "      RatingCount  ReviewCount         Brand  Price  \\\n",
       "1605      11721.0       6955.0         paris   9.97   \n",
       "2989        505.0        326.0        redken  30.00   \n",
       "975         246.0        220.0         suave  13.53   \n",
       "2755       2257.0       2070.0           men  40.68   \n",
       "3666        796.0        425.0           ogx  21.00   \n",
       "1672        571.0        336.0       pantene  36.98   \n",
       "1701         56.0         53.0         splat   6.89   \n",
       "3600        175.0          0.0       biosilk  25.87   \n",
       "2434        164.0        142.0       pantene  29.90   \n",
       "3013        157.0          0.0  oils, center  12.19   \n",
       "\n",
       "                                                   Tags  \n",
       "1605  paris, magic, root, cover, concealer, spray, b...  \n",
       "2989  redken, color, extend, magnetics, sulfate, fre...  \n",
       "975   suave, professionals, coconut, milk, infusion,...  \n",
       "2755  men, color, gel, mustache, beard, medium, brow...  \n",
       "3666  ogx, straightening, brazilian, keratin, therap...  \n",
       "1672  pantene, pro, v, classic, clean, 2, 1, shampoo...  \n",
       "1701         splat, hair, chalk, sugar, plum, wal, mart  \n",
       "3600  volumizing, therapy, shampoo, biosilk, unisex,...  \n",
       "2434  pantene, pro, v, smooth, sleek, conditioner, f...  \n",
       "3013  blue, neon, colorant, pigment, powder, crafts,...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_name = \"shampoo\"  \n",
    "\n",
    "recommended_items = content_based_recommendations2(\n",
    "    train_data=df,\n",
    "    item_name=item_name,\n",
    "    top_n=10 \n",
    ")\n",
    "\n",
    "recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f3e0b-6a19-4a0d-9afb-0ff7478554d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_name = \"Hair Product\"  \n",
    "\n",
    "recommended_items = content_based_recommendations2(\n",
    "    train_data=df,\n",
    "    item_name=item_name,\n",
    "    top_n=10 \n",
    ")\n",
    "\n",
    "recommended_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e142abc7-ca3e-469d-892a-9d559ddbd4d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Search Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e2d50b6-0ea8-4eea-ae1b-a633132279cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_top = gt1.sort_values(by='Rating', ascending=False).head(20)\n",
    "ground_truth_top2 = gt2.sort_values(by='Rating', ascending=False).head(20)\n",
    "ground_truth_top3 = gt3.sort_values(by='Rating', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6dc00e2-ebaa-48be-869d-454e72693a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations(train_data, ground_truth, query, top_n=20):\n",
    "    \"\"\"\n",
    "    Evaluates the content-based recommendation system based on the ground truth.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: The full dataset containing product information (df).\n",
    "    - ground_truth: The ground truth dataset (manually labeled relevant products, df2).\n",
    "    - query: The search query used to generate recommendations.\n",
    "    - top_n: Number of top recommendations to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision score for the recommendations.\n",
    "    - recall: Recall score for the recommendations.\n",
    "    - f1: F1-Score for the recommendations.\n",
    "    - accuracy: Accuracy score for the recommendations.\n",
    "    - map_score: Mean Average Precision (MAP) score.\n",
    "    - ndcg: Normalized Discounted Cumulative Gain (NDCG) score.\n",
    "    \"\"\"\n",
    "    recommended_items = content_based_recommendations(train_data, query, top_n=top_n)\n",
    "    \n",
    "    recommended_prod_ids = recommended_items['ProdID'].values\n",
    "    relevant_prod_ids = ground_truth['ProdID'].values\n",
    "    \n",
    "    y_true = [1 if prod_id in relevant_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    y_pred = [1 if prod_id in recommended_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_pred_scores = [1 if prod_id in recommended_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    map_score = average_precision_score(y_true, y_pred_scores)\n",
    "\n",
    "    relevant_labels = [1 if prod_id in relevant_prod_ids else 0 for prod_id in recommended_prod_ids]\n",
    "    ndcg = ndcg_score([relevant_labels], [y_pred_scores[:top_n]])\n",
    "\n",
    "    return precision, recall, f1, accuracy, map_score, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acf52f0-b7de-4bb8-a24e-b2593faf8fb6",
   "metadata": {},
   "source": [
    "### Hair Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a83c88cb-f44b-4d20-a118-c9069df0ff7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'intersection hair hair's-breadth Cartesian product production merchandise mathematical product haircloth fuzz whisker hairsbreadth pilus product tomentum ware'. Showing similar items.\n",
      "Precision: 0.4078, Recall: 0.4738, F1: 0.4383, Accuracy: 0.7042\n",
      "MAP: 0.3214, NDCG: 0.5704\n"
     ]
    }
   ],
   "source": [
    "query = \"Hair Product\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b7be79c-42d0-4f88-92c8-7e074c873317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'hair block out cloak dissemble masquerade disguise haircloth fuzz whisker masque hairsbreadth pilus hair's-breadth tomentum masquerade party mask'. Showing similar items.\n",
      "Precision: 0.4085, Recall: 0.4738, F1: 0.4388, Accuracy: 0.7047\n",
      "MAP: 0.3217, NDCG: 0.4953\n"
     ]
    }
   ],
   "source": [
    "query = \"Hair mask\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffcdedb4-3f8d-481f-a4df-70e5cb107abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'shampoo'. Showing similar items.\n",
      "Precision: 0.5944, Recall: 0.7696, F1: 0.6708, Accuracy: 0.8160\n",
      "MAP: 0.5136, NDCG: 0.7976\n"
     ]
    }
   ],
   "source": [
    "query = \"Shampoo\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05d9193f-b0a3-45d3-a277-0eea349fd3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'consideration status term condition stipulate qualify circumstance specify discipline precondition experimental condition train shape stipulation check'. Showing similar items.\n",
      "Precision: 0.4701, Recall: 0.4738, F1: 0.4719, Accuracy: 0.7417\n",
      "MAP: 0.3509, NDCG: 0.6871\n"
     ]
    }
   ],
   "source": [
    "query = \"conditioner\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a4f7c29-ada5-4a72-8fe0-be53e25ceb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'intersection hair hair's-breadth Cartesian product production merchandise mathematical product haircloth fuzz whisker hairsbreadth pilus product tomentum ware'. Showing similar items.\n",
      "Found match for 'hair block out cloak dissemble masquerade disguise haircloth fuzz whisker masque hairsbreadth pilus hair's-breadth tomentum masquerade party mask'. Showing similar items.\n",
      "Found match for 'shampoo'. Showing similar items.\n",
      "Found match for 'consideration status term condition stipulate qualify circumstance specify discipline precondition experimental condition train shape stipulation check'. Showing similar items.\n",
      "Average Precision: 0.4702\n",
      "Average Recall: 0.5478\n",
      "Average F1-Score: 0.5049\n",
      "Average Accuracy: 0.7417\n",
      "Average MAP: 0.3769\n",
      "Average NDCG: 0.6376\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Hair Product\", \"Hair mask\", \"Shampoo\", \"Conditioner\"]\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations(df, ground_truth_top, query, top_n=20)\n",
    "    \n",
    "    # Accumulate the metrics\n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "# Calculate the average metrics across all queries\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "# Print the averaged results\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96afd612-32ae-48f2-80da-7effd585da14",
   "metadata": {},
   "source": [
    "### HouseHolds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce6e8c71-ab6b-4ba7-8d7b-e8c6e7bc2ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'household house menage family home'. Showing similar items.\n",
      "Precision: 0.6804, Recall: 0.8094, F1: 0.7393, Accuracy: 0.8606\n",
      "MAP: 0.5973, NDCG: 0.7260\n"
     ]
    }
   ],
   "source": [
    "query = \"Households\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c755d62-16b0-4522-9f73-90de4c58ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'deterg'. Showing similar items.\n",
      "Precision: 0.5983, Recall: 0.7934, F1: 0.6822, Accuracy: 0.8194\n",
      "MAP: 0.5252, NDCG: 0.7163\n"
     ]
    }
   ],
   "source": [
    "query = \"Detergent\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0049587e-dea2-4572-ab30-d253940e61d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'cleanse fairly light uncontaminating clear fresh strip sporting clean house clean-living uninfected houseclean plumb white clean blank make clean unclouded neat unobjectionable fair sportsmanlike scavenge clean and jerk plum pick sporty'. Showing similar items.\n",
      "Precision: 0.3072, Recall: 0.2989, F1: 0.3030, Accuracy: 0.6641\n",
      "MAP: 0.2631, NDCG: 0.4066\n"
     ]
    }
   ],
   "source": [
    "query = \"Cleaning\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4778a8a5-1aa5-46d0-9228-393408f69f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'base menage plate nursing home abode habitation household family interior national domicile dwelling house rest home place home dwelling house home plate home base internal'. Showing similar items.\n",
      "Precision: 0.6067, Recall: 0.6189, F1: 0.6127, Accuracy: 0.8089\n",
      "MAP: 0.4686, NDCG: 0.7862\n"
     ]
    }
   ],
   "source": [
    "query = \"Home\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f5da028-a6eb-4099-85e9-44853de5bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'household house menage family home'. Showing similar items.\n",
      "Found match for 'deterg'. Showing similar items.\n",
      "Found match for 'cleanse fairly light uncontaminating clear fresh strip sporting clean house clean-living uninfected houseclean plumb white clean blank make clean unclouded neat unobjectionable fair sportsmanlike scavenge clean and jerk plum pick sporty'. Showing similar items.\n",
      "Found match for 'base menage plate nursing home abode habitation household family interior national domicile dwelling house rest home place home dwelling house home plate home base internal'. Showing similar items.\n",
      "Average Precision: 0.5482\n",
      "Average Recall: 0.6301\n",
      "Average F1-Score: 0.5843\n",
      "Average Accuracy: 0.7882\n",
      "Average MAP: 0.4635\n",
      "Average NDCG: 0.6588\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Households\", \"Detergent\", \"Cleaning\", \"Home\"]\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations(df, ground_truth_top2, query, top_n=20)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54e2890-5929-4ccd-a27a-94ffdb9bb285",
   "metadata": {},
   "source": [
    "### Beauty Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41ca3727-4e5c-4af3-a0db-ea364d79c7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'beauti'. Showing similar items.\n",
      "Precision: 0.4005, Recall: 0.5709, F1: 0.4708, Accuracy: 0.7405\n",
      "MAP: 0.3154, NDCG: 0.6313\n"
     ]
    }
   ],
   "source": [
    "query = \"Beauty\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc6fe627-9382-4a8f-9f0b-4355e6d8f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'makeup composition war paint make-up constitution physical composition'. Showing similar items.\n",
      "Precision: 0.5673, Recall: 0.5879, F1: 0.5774, Accuracy: 0.8260\n",
      "MAP: 0.4168, NDCG: 0.5497\n"
     ]
    }
   ],
   "source": [
    "query = \"makeup\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "644d98b0-c8a3-4c3c-9c5c-94a489ecd4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'lotion application'. Showing similar items.\n",
      "Precision: 0.5495, Recall: 0.5455, F1: 0.5474, Accuracy: 0.8177\n",
      "MAP: 0.3916, NDCG: 0.4964\n"
     ]
    }
   ],
   "source": [
    "query = \"Lotion\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5b0d3fb-762f-481c-b320-d629133cdad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'lipstick lip rouge'. Showing similar items.\n",
      "Precision: 0.4181, Recall: 0.5879, F1: 0.4887, Accuracy: 0.7513\n",
      "MAP: 0.3291, NDCG: 0.5089\n"
     ]
    }
   ],
   "source": [
    "query = \"Lipstick\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "956e46c0-c2fe-4c36-ab0d-c0becc12df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'beauti'. Showing similar items.\n",
      "Found match for 'makeup composition war paint make-up constitution physical composition'. Showing similar items.\n",
      "Found match for 'lotion application'. Showing similar items.\n",
      "Found match for 'lipstick lip rouge'. Showing similar items.\n",
      "Average Precision: 0.4838\n",
      "Average Recall: 0.5730\n",
      "Average F1-Score: 0.5211\n",
      "Average Accuracy: 0.7839\n",
      "Average MAP: 0.3632\n",
      "Average NDCG: 0.5466\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Beauty\", \"Makeup\", \"Lotion\", \"Lipstick\"]\n",
    "\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations(df, ground_truth_top3, query, top_n=20)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dec33a2-0e3a-4fdc-864b-fb445ce80965",
   "metadata": {},
   "source": [
    "### Combined Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8efa2044-c31a-4b60-9eae-fc30959de3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match for 'beauti'. Showing similar items.\n",
      "Found match for 'makeup composition war paint make-up constitution physical composition'. Showing similar items.\n",
      "Found match for 'lotion application'. Showing similar items.\n",
      "Found match for 'lipstick lip rouge'. Showing similar items.\n",
      "Found match for 'household house menage family home'. Showing similar items.\n",
      "Found match for 'deterg'. Showing similar items.\n",
      "Found match for 'cleanse fairly light uncontaminating clear fresh strip sporting clean house clean-living uninfected houseclean plumb white clean blank make clean unclouded neat unobjectionable fair sportsmanlike scavenge clean and jerk plum pick sporty'. Showing similar items.\n",
      "Found match for 'base menage plate nursing home abode habitation household family interior national domicile dwelling house rest home place home dwelling house home plate home base internal'. Showing similar items.\n",
      "Found match for 'intersection hair hair's-breadth Cartesian product production merchandise mathematical product haircloth fuzz whisker hairsbreadth pilus product tomentum ware'. Showing similar items.\n",
      "Found match for 'hair block out cloak dissemble masquerade disguise haircloth fuzz whisker masque hairsbreadth pilus hair's-breadth tomentum masquerade party mask'. Showing similar items.\n",
      "Found match for 'shampoo'. Showing similar items.\n",
      "Found match for 'consideration status term condition stipulate qualify circumstance specify discipline precondition experimental condition train shape stipulation check'. Showing similar items.\n",
      "Final Combined Average Precision: 0.5426\n",
      "Final Combined Average Recall: 0.6334\n",
      "Final Combined Average F1-Score: 0.5791\n",
      "Final Combined Average Accuracy: 0.7916\n",
      "Final Combined Average MAP: 0.4484\n",
      "Final Combined Average NDCG: 0.6312\n"
     ]
    }
   ],
   "source": [
    "query_sets_with_ground_truth = [\n",
    "    ([\"Beauty\", \"Makeup\", \"Lotion\", \"Lipstick\"], ground_truth_top),      \n",
    "    ([\"Households\", \"Detergent\", \"Cleaning\", \"Home\"], ground_truth_top2), \n",
    "    ([\"Hair Product\", \"Hair mask\", \"Shampoo\", \"Conditioner\"], ground_truth_top3) \n",
    "]\n",
    "\n",
    "combined_precision = combined_recall = combined_f1 = combined_accuracy = combined_map = combined_ndcg = 0\n",
    "total_queries = 0\n",
    "\n",
    "for queries, ground_truth in query_sets_with_ground_truth:\n",
    "    total_precision = total_recall = total_f1 = total_accuracy = total_map = total_ndcg = 0\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    for query in queries:\n",
    "        precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations(df, ground_truth, query, top_n=20)\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "        total_accuracy += accuracy\n",
    "        total_map += map_score\n",
    "        total_ndcg += ndcg\n",
    "\n",
    "    avg_precision = total_precision / num_queries\n",
    "    avg_recall = total_recall / num_queries\n",
    "    avg_f1 = total_f1 / num_queries\n",
    "    avg_accuracy = total_accuracy / num_queries\n",
    "    avg_map = total_map / num_queries\n",
    "    avg_ndcg = total_ndcg / num_queries\n",
    "    \n",
    "    combined_precision += avg_precision\n",
    "    combined_recall += avg_recall\n",
    "    combined_f1 += avg_f1\n",
    "    combined_accuracy += avg_accuracy\n",
    "    combined_map += avg_map\n",
    "    combined_ndcg += avg_ndcg\n",
    "    total_queries += 1\n",
    "\n",
    "final_avg_precision = combined_precision / total_queries\n",
    "final_avg_recall = combined_recall / total_queries\n",
    "final_avg_f1 = combined_f1 / total_queries\n",
    "final_avg_accuracy = combined_accuracy / total_queries\n",
    "final_avg_map = combined_map / total_queries\n",
    "final_avg_ndcg = combined_ndcg / total_queries\n",
    "\n",
    "print(f\"Final Combined Average Precision: {final_avg_precision:.4f}\")\n",
    "print(f\"Final Combined Average Recall: {final_avg_recall:.4f}\")\n",
    "print(f\"Final Combined Average F1-Score: {final_avg_f1:.4f}\")\n",
    "print(f\"Final Combined Average Accuracy: {final_avg_accuracy:.4f}\")\n",
    "print(f\"Final Combined Average MAP: {final_avg_map:.4f}\")\n",
    "print(f\"Final Combined Average NDCG: {final_avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c3f13d-1ae2-4990-b5eb-9d412e85eb87",
   "metadata": {},
   "source": [
    "## Evaluation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "539d5322-a399-4525-aa27-86217c761ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_recommendations2(train_data, ground_truth, query, top_n=20):\n",
    "    \"\"\"\n",
    "    Evaluates the content-based recommendation system based on the ground truth.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: The full dataset containing product information (df).\n",
    "    - ground_truth: The ground truth dataset (manually labeled relevant products, df2).\n",
    "    - query: The search query used to generate recommendations.\n",
    "    - top_n: Number of top recommendations to evaluate.\n",
    "    \n",
    "    Returns:\n",
    "    - precision: Precision score for the recommendations.\n",
    "    - recall: Recall score for the recommendations.\n",
    "    - f1: F1-Score for the recommendations.\n",
    "    - accuracy: Accuracy score for the recommendations.\n",
    "    - map_score: Mean Average Precision (MAP) score.\n",
    "    - ndcg: Normalized Discounted Cumulative Gain (NDCG) score.\n",
    "    \"\"\"\n",
    "    recommended_items = content_based_recommendations2(train_data, query, top_n=top_n)\n",
    "    \n",
    "    recommended_prod_ids = recommended_items['ProdID'].values\n",
    "    relevant_prod_ids = ground_truth['ProdID'].values\n",
    "    \n",
    "    y_true = [1 if prod_id in relevant_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    y_pred = [1 if prod_id in recommended_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    \n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    y_pred_scores = [1 if prod_id in recommended_prod_ids else 0 for prod_id in train_data['ProdID']]\n",
    "    map_score = average_precision_score(y_true, y_pred_scores)\n",
    "\n",
    "    relevant_labels = [1 if prod_id in relevant_prod_ids else 0 for prod_id in recommended_prod_ids]\n",
    "    ndcg = ndcg_score([relevant_labels], [y_pred_scores[:top_n]])\n",
    "\n",
    "    return precision, recall, f1, accuracy, map_score, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fb2e87-767f-4929-8d20-c880660b3808",
   "metadata": {},
   "source": [
    "### Hair Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a8bb275-12ae-4d27-b022-4ebfad83465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5582, Recall: 0.9648, F1: 0.7072, Accuracy: 0.8054\n",
      "MAP: 0.5471, NDCG: 0.7603\n"
     ]
    }
   ],
   "source": [
    "query = \"Hair Product\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ee217ae-5876-4542-ac5b-95e978a7a260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5566, Recall: 0.9648, F1: 0.7059, Accuracy: 0.8042\n",
      "MAP: 0.5456, NDCG: 0.5805\n"
     ]
    }
   ],
   "source": [
    "query = \"Hair mask\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e48b025-d6ea-49b8-9f9e-18b45ec5636a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5675, Recall: 0.9648, F1: 0.7146, Accuracy: 0.8123\n",
      "MAP: 0.5561, NDCG: 0.7603\n"
     ]
    }
   ],
   "source": [
    "query = \"Shampoo\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50b02aa3-86dc-4c10-8267-1c53dcd26e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5563, Recall: 0.9497, F1: 0.7016, Accuracy: 0.8032\n",
      "MAP: 0.5405, NDCG: 0.6454\n"
     ]
    }
   ],
   "source": [
    "query = \"conditioner\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a168e710-55d4-4855-8d6d-906d05ce50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.5596\n",
      "Average Recall: 0.9610\n",
      "Average F1-Score: 0.7073\n",
      "Average Accuracy: 0.8063\n",
      "Average MAP: 0.5473\n",
      "Average NDCG: 0.6866\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Hair Product\", \"Hair mask\", \"Shampoo\", \"Conditioner\"]\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations2(df, ground_truth_top, query, top_n=20)\n",
    "    \n",
    "    # Accumulate the metrics\n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "# Calculate the average metrics across all queries\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "# Print the averaged results\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac9bb2-620d-44f4-bd8f-bc1ec3673d7d",
   "metadata": {},
   "source": [
    "### Household Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8658582f-15dd-4dd2-a386-22ae17a8c725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5675, Recall: 0.9609, F1: 0.7136, Accuracy: 0.8116\n",
      "MAP: 0.5549, NDCG: 0.7254\n"
     ]
    }
   ],
   "source": [
    "query = \"Households\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0bc4221f-034f-436a-b343-5c8399e553f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6349, Recall: 0.9348, F1: 0.7562, Accuracy: 0.8527\n",
      "MAP: 0.6094, NDCG: 0.8256\n"
     ]
    }
   ],
   "source": [
    "query = \"Detergent\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa8bbc74-dbb5-4553-9a7a-a3054237877c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match['Score'] = score / 100 * fuzzy_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5480, Recall: 0.9509, F1: 0.6953, Accuracy: 0.7964\n",
      "MAP: 0.5331, NDCG: 0.7055\n"
     ]
    }
   ],
   "source": [
    "query = \"Cleaning\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "79f012f5-b09b-4299-aa49-e4ccee2114e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5403, Recall: 0.9338, F1: 0.6846, Accuracy: 0.7898\n",
      "MAP: 0.5207, NDCG: 0.6313\n"
     ]
    }
   ],
   "source": [
    "query = \"Home\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top2, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2f9c5f6-217b-4413-b8c4-47964dd9d161",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match['Score'] = score / 100 * fuzzy_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.5727\n",
      "Average Recall: 0.9451\n",
      "Average F1-Score: 0.7124\n",
      "Average Accuracy: 0.8126\n",
      "Average MAP: 0.5545\n",
      "Average NDCG: 0.7219\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Households\", \"Detergent\", \"Cleaning\", \"Home\"]\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations2(df, ground_truth_top2, query, top_n=20)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0698a9-7f3f-4951-b6d7-9377e92c1775",
   "metadata": {},
   "source": [
    "### Beauty Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39a0f2c3-e31b-4206-a32b-615a84cb3680",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4766, Recall: 0.9612, F1: 0.6372, Accuracy: 0.7787\n",
      "MAP: 0.4659, NDCG: 0.6313\n"
     ]
    }
   ],
   "source": [
    "query = \"Beauty\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8037da0-a64a-4a3c-bc89-ff80055d5758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4604, Recall: 0.9455, F1: 0.6193, Accuracy: 0.7650\n",
      "MAP: 0.4464, NDCG: 0.6451\n"
     ]
    }
   ],
   "source": [
    "query = \"Makeup\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e5daaba8-ddfe-412f-9e36-10375074d23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4657, Recall: 0.9455, F1: 0.6240, Accuracy: 0.7697\n",
      "MAP: 0.4513, NDCG: 0.6451\n"
     ]
    }
   ],
   "source": [
    "query = \"Lotion\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3f1d1029-6d7e-4818-a91d-e26e846d9b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4662, Recall: 0.9455, F1: 0.6245, Accuracy: 0.7702\n",
      "MAP: 0.4518, NDCG: 0.6451\n"
     ]
    }
   ],
   "source": [
    "query = \"Lipstick\"\n",
    "precision, recall, f1, accuracy, map_score,  ndcg = evaluate_recommendations2(df, ground_truth_top3, query ,top_n=20)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(f\"MAP: {map_score:.4f}, NDCG: {ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cef517a8-79e9-4bd0-9abb-328cbb206be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision: 0.4672\n",
      "Average Recall: 0.9494\n",
      "Average F1-Score: 0.6262\n",
      "Average Accuracy: 0.7709\n",
      "Average MAP: 0.4539\n",
      "Average NDCG: 0.6417\n"
     ]
    }
   ],
   "source": [
    "queries = [\"Beauty\", \"Makeup\", \"Lotion\", \"Lipstick\"]\n",
    "\n",
    "\n",
    "total_precision, total_recall, total_f1, total_accuracy, total_map, total_ndcg = 0, 0, 0, 0, 0, 0\n",
    "num_queries = len(queries)\n",
    "\n",
    "for query in queries:\n",
    "    precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations2(df, ground_truth_top3, query, top_n=20)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "    total_f1 += f1\n",
    "    total_accuracy += accuracy\n",
    "    total_map += map_score\n",
    "    total_ndcg += ndcg\n",
    "\n",
    "avg_precision = total_precision / num_queries\n",
    "avg_recall = total_recall / num_queries\n",
    "avg_f1 = total_f1 / num_queries\n",
    "avg_accuracy = total_accuracy / num_queries\n",
    "avg_map = total_map / num_queries\n",
    "avg_ndcg = total_ndcg / num_queries\n",
    "\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1-Score: {avg_f1:.4f}\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average MAP: {avg_map:.4f}\")\n",
    "print(f\"Average NDCG: {avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d697937e-3ce9-4eab-97c4-d9b3a7f7a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  match['Score'] = score / 100 * fuzzy_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n",
      "C:\\Users\\Daniel Matias\\AppData\\Local\\Temp\\ipykernel_13796\\2732457779.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  category_matches.loc[:, 'Score'] = category_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Combined Average Precision: 0.5306\n",
      "Final Combined Average Recall: 0.9466\n",
      "Final Combined Average F1-Score: 0.6782\n",
      "Final Combined Average Accuracy: 0.7939\n",
      "Final Combined Average MAP: 0.5144\n",
      "Final Combined Average NDCG: 0.6507\n"
     ]
    }
   ],
   "source": [
    "query_sets_with_ground_truth = [\n",
    "    ([\"Beauty\", \"Makeup\", \"Lotion\", \"Lipstick\"], ground_truth_top),      \n",
    "    ([\"Households\", \"Detergent\", \"Cleaning\", \"Home\"], ground_truth_top2), \n",
    "    ([\"Hair Product\", \"Hair mask\", \"Shampoo\", \"Conditioner\"], ground_truth_top3) \n",
    "]\n",
    "\n",
    "combined_precision = combined_recall = combined_f1 = combined_accuracy = combined_map = combined_ndcg = 0\n",
    "total_queries = 0\n",
    "\n",
    "for queries, ground_truth in query_sets_with_ground_truth:\n",
    "    total_precision = total_recall = total_f1 = total_accuracy = total_map = total_ndcg = 0\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    for query in queries:\n",
    "        precision, recall, f1, accuracy, map_score, ndcg = evaluate_recommendations2(df, ground_truth, query, top_n=20)\n",
    "        \n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_f1 += f1\n",
    "        total_accuracy += accuracy\n",
    "        total_map += map_score\n",
    "        total_ndcg += ndcg\n",
    "\n",
    "    avg_precision = total_precision / num_queries\n",
    "    avg_recall = total_recall / num_queries\n",
    "    avg_f1 = total_f1 / num_queries\n",
    "    avg_accuracy = total_accuracy / num_queries\n",
    "    avg_map = total_map / num_queries\n",
    "    avg_ndcg = total_ndcg / num_queries\n",
    "    \n",
    "    combined_precision += avg_precision\n",
    "    combined_recall += avg_recall\n",
    "    combined_f1 += avg_f1\n",
    "    combined_accuracy += avg_accuracy\n",
    "    combined_map += avg_map\n",
    "    combined_ndcg += avg_ndcg\n",
    "    total_queries += 1\n",
    "\n",
    "final_avg_precision = combined_precision / total_queries\n",
    "final_avg_recall = combined_recall / total_queries\n",
    "final_avg_f1 = combined_f1 / total_queries\n",
    "final_avg_accuracy = combined_accuracy / total_queries\n",
    "final_avg_map = combined_map / total_queries\n",
    "final_avg_ndcg = combined_ndcg / total_queries\n",
    "\n",
    "print(f\"Final Combined Average Precision: {final_avg_precision:.4f}\")\n",
    "print(f\"Final Combined Average Recall: {final_avg_recall:.4f}\")\n",
    "print(f\"Final Combined Average F1-Score: {final_avg_f1:.4f}\")\n",
    "print(f\"Final Combined Average Accuracy: {final_avg_accuracy:.4f}\")\n",
    "print(f\"Final Combined Average MAP: {final_avg_map:.4f}\")\n",
    "print(f\"Final Combined Average NDCG: {final_avg_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca544fb2-c53f-4289-a89e-f84c70d20d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a29b3f-52ca-4287-b68c-ce1c4efce7f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8577881-aee7-4a65-84ff-dda89670953a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_env)",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
